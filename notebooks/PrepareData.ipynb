{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import dateutil.parser\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from UKMovementSensing import dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = '/media/sf_VBox_Shared/London/raw/next161/'\n",
    "annotations_path = output_path + 'tud_next161_deb.csv'\n",
    "wearcodes_path = output_path + 'wearcodes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = output_path + 'accelerometer_5second/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing start and end times: 0 0\n",
      "Multiple end times per slot. first 10:\n",
      "Slot\n",
      "1     [04:10:00]\n",
      "2     [04:20:00]\n",
      "3     [04:30:00]\n",
      "4     [04:40:00]\n",
      "5     [04:50:00]\n",
      "6     [05:00:00]\n",
      "7     [05:10:00]\n",
      "8     [05:20:00]\n",
      "9     [05:30:00]\n",
      "10    [05:40:00]\n",
      "Name: end_time_time, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't compare offset-naive and offset-aware datetimes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ae1f79ad4c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mannotations_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_wearcodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwearcodes_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_codes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_merged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'merged/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_subsequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dafne/timeseries/UKMovementSensing/UKMovementSensing/dataprep.py\u001b[0m in \u001b[0;36mprocess_data\u001b[1;34m(annotations_codes, filepath)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# Add annotations:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[1;31m# Keep all data frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dafne/timeseries/UKMovementSensing/UKMovementSensing/dataprep.py\u001b[0m in \u001b[0;36madd_annotations\u001b[1;34m(df, binfile, day, annotations_group)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mfirsttime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mfirsttime\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#firsttime.tz_localize('UTC') != min(annotations_group.start_time) :\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'starttime of data does not correspond with starttime of annotations!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirsttime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib._Timestamp.__richcmp__ (pandas/tslib.c:18101)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't compare offset-naive and offset-aware datetimes"
     ]
    }
   ],
   "source": [
    "annotations = dataprep.process_annotations(annotations_path)\n",
    "annotations_codes = dataprep.join_wearcodes(wearcodes_path, annotations)\n",
    "dfs = dataprep.process_data(annotations_codes, file_path)\n",
    "dataprep.save_merged(dfs, os.path.join(output_path, 'merged/'))\n",
    "subsets = dataprep.take_subsequences(dfs)\n",
    "dataprep.save_subsequences(subsets, os.path.join(output_path, 'subsets/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(annotations.shape)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To check: Do we have any gaps?\n",
    "for i in range(1, annotations.shape[0]):\n",
    "    if annotations['serflag'][i]==annotations['serflag'][i-1] and annotations['tud_day'][i]==annotations['tud_day'][i-1]:\n",
    "        if (annotations['end_time'][i-1] != annotations['start_time'][i]):\n",
    "            print(annotations.loc[[i-1, i],['start_time', 'end_time']])\n",
    "            print(annotations['end_time'][i-1] - annotations['start_time'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate join with wearcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(annotations_codes.shape)\n",
    "annotations_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_key = dfs.keys()[0]\n",
    "binfile, day = example_key\n",
    "df = dfs[example_key]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = df.index[0]\n",
    "print(t.tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create boxplots for each sequence for the angles\n",
    "#We expect x (and thus anglex) to be distributed either mostly on the negative or mostly on the positive half\n",
    "fig, axes = plt.subplots(len(subsets.values()), figsize=(10, 50))\n",
    "for i, dataset in enumerate(subsets.values()):\n",
    "    non_sleeping_indices = dataset['act'] != 1.0\n",
    "    non_sleeping = dataset[non_sleeping_indices]\n",
    "    print(np.median(non_sleeping['anglex']), np.median(non_sleeping['angley']))\n",
    "    axes[i].boxplot([non_sleeping['anglex'], non_sleeping['angley'], non_sleeping['anglez']], labels=['x', 'y', 'z']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subsets = dataprep.switch_positions(subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create boxplots for each sequence for the angles\n",
    "#We expect x (and thus anglex) to be distributed either mostly on the negative or mostly on the positive half\n",
    "fig, axes = plt.subplots(len(subsets.values()), figsize=(10, 50))\n",
    "for i, dataset in enumerate(subsets.values()):\n",
    "    non_sleeping_indices = dataset['act'] != 1.0\n",
    "    non_sleeping = dataset[non_sleeping_indices]\n",
    "    print(np.median(non_sleeping['anglex']), np.median(non_sleeping['angley']))\n",
    "    axes[i].boxplot([non_sleeping['anglex'], non_sleeping['angley'], non_sleeping['anglez']], labels=['x', 'y', 'z']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
